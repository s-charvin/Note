---
title: "Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph"
description: ""
citekey: bagherzadehMultimodalLanguageAnalysis2018
author: "石昌文"
tags: [""]
categories: "PaperNote"
keywords:  [""]
draft: true
layout: "blog"
date: 2023-06-04 18:21:02
lastmod: 2023-06-05 15:47:29
---

> [!info] 论文信息
>1. Title：Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph
>2. Author：AmirAli Bagher Zadeh, Paul Pu Liang, Soujanya Poria, Erik Cambria, Louis-Philippe Morency
>3. Entry：[Zotero link](zotero://select/items/@bagherzadehMultimodalLanguageAnalysis2018) [URL link](https://aclanthology.org/P18-1208) [PDF link](<file:///C\:\\Users\\19115\\OneDrive - stu.suda.edu.cn\\Zotero\\Bagher Zadeh et al_2018_Multimodal Language Analysis in the Wild.pdf>)
>4. Other：2018 - Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)  Association for Computational Linguistics Melbourne, Australia  -   

>- :luc_github: 论文实现：
>- :luc_external_link: 论文解读：
>- :luc_linkedin: 相关笔记：***

## ⭐ 重点

- :fas_question:   
- :obs_pdf_file:   
- :obs_graph_glyph:   
- :obs_wand_glyph:   

## 摘要

> [!abstract] Analyzing human multimodal language is an emerging area of research in NLP. Intrinsically this language is multimodal (heterogeneous), sequential and asynchronous; it consists of the language (words), visual (expressions) and acoustic (paralinguistic) modalities all in the form of asynchronous coordinated sequences. From a resource perspective, there is a genuine need for large scale datasets that allow for in-depth studies of this form of language. In this paper we introduce CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI), the largest dataset of sentiment analysis and emotion recognition to date. Using data from CMU-MOSEI and a novel multimodal fusion technique called the Dynamic Fusion Graph (DFG), we conduct experimentation to exploit how modalities interact with each other in human multimodal language. Unlike previously proposed fusion techniques, DFG is highly interpretable and achieves competative performance when compared to the previous state of the art.

> 分析人类多模态语言是 NLP 的一个新兴研究领域。从本质上讲，人类交流是多模式的（异质的）、时间的和异步的；它由语言（单词）、视觉（表达）和听觉（副语言）模态组成，所有模态均以异步协调序列的形式出现。从资源的角度来看，真正需要能够深入研究多模态语言的大规模数据集。在本文中，我们介绍了 CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI)，这是迄今为止最大的情感分析和情感识别数据集。使用来自 CMU-MOSEI 的数据和一种称为动态融合图 (DFG) 的新型多模态融合技术，我们进行实验以研究模态如何在人类多模态语言中相互作用。与之前提出的融合技术不同，DFG 具有高度可解释性，并且与当前最先进的技术相比具有竞争力的性能。

## 预处理

## 概述

## 结果

## 精读

### 引文

## 摘录
