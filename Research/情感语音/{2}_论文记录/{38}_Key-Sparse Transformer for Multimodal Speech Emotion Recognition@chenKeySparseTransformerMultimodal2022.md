---
title: "Key-Sparse Transformer for Multimodal Speech Emotion Recognition"
description: ""
citekey: chenKeySparseTransformerMultimodal2022
author: "石昌文"
tags: [""]
categories: "PaperNote"
keywords:  [""]
draft: true
layout: "blog"
---

> [!info] 论文信息
>1. Title：Key-Sparse Transformer for Multimodal Speech Emotion Recognition
>2. Author：Weidong Chen, Xiaofeng Xing, Xiangmin Xu, Jichen Yang, Jianxin Pang
>3. Entry：[Zotero link](zotero://select/items/@chenKeySparseTransformerMultimodal2022) [URL link]() [PDF link](<file:///C\:\\Users\\19115\\OneDrive - stu.suda.edu.cn\\Zotero\\Chen et al_2022_Key-Sparse Transformer for Multimodal Speech Emotion Recognition.pdf>)
>4. Other：2022 - ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)     -   

>- :luc_github: 论文实现：
>- :luc_external_link: 论文解读：
>- :luc_linkedin: 相关笔记：***


## ⭐ 重点

- 

## 摘要

> [!abstract] Speech emotion recognition is a challenging research topic that plays a critical role in human-computer interaction. Multimodal inputs further improve the performance as more emotional information is used. However, existing studies learn all the information in the sample while only a small portion of it is about emotion. The redundant information will become noises and limit the system performance. In this paper, a key-sparse Transformer is proposed for efficient emotion recognition by focusing more on emotion related information. The proposed method is evaluated on the IEMOCAP and LSSED. Experimental results show that the proposed method achieves better performance than the state-of-the-art approaches.

> 

## 预处理

## 概述

## 结果

## 精读

### 引文

## 摘录
