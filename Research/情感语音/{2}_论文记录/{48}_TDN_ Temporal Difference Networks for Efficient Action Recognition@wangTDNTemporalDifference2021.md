---
title: "TDN: Temporal Difference Networks for Efficient Action Recognition"
description: ""
citekey: wangTDNTemporalDifference2021
author: "石昌文"
tags: [""]
categories: "PaperNote"
keywords:  [""]
draft: true
layout: "blog"
date: 2023-02-15 14:36:33
lastmod: 2023-04-11 13:07:07
---

> [!info] 论文信息
>1. Title：TDN: Temporal Difference Networks for Efficient Action Recognition
>2. Author：Limin Wang, Zhan Tong, Bin Ji, Gangshan Wu
>3. Entry：[Zotero link](zotero://select/items/@wangTDNTemporalDifference2021) [URL link](http://arxiv.org/abs/2012.10071) [PDF link](<file:///C\:\\Users\\19115\\OneDrive - stu.suda.edu.cn\\Zotero\\Wang et al_2021_TDN.pdf,E\:\\mypack\\人生规划\\ 3 _进修\\ 2 _升学\\ 4 _硕士学习\\ 4 _研究\\Zotero\\storage\\ERLRPUZY\\2012.html>)
>4. Other：2021 - arxiv:2012.10071 [cs]  arXiv   -   

>- :luc_github: 论文实现：https://github.com/MCG-NJU/TDN
>- :luc_external_link: 论文解读：
>- :luc_linkedin: 相关笔记：***

## ⭐ 重点

- 

## 摘要

> [!abstract] Temporal modeling still remains challenging for action recognition in videos. To mitigate this issue, this paper presents a new video architecture, termed as Temporal Difference Network (TDN), with a focus on capturing multi-scale temporal information for efficient action recognition. The core of our TDN is to devise an efficient temporal module (TDM) by explicitly leveraging a temporal difference operator, and systematically assess its effect on short-term and long-term motion modeling. To fully capture temporal information over the entire video, our TDN is established with a two-level difference modeling paradigm. Specifically, for local motion modeling, temporal difference over consecutive frames is used to supply 2D CNNs with finer motion pattern, while for global motion modeling, temporal difference across segments is incorporated to capture long-range structure for motion feature excitation. TDN provides a simple and principled temporal modeling framework and could be instantiated with the existing CNNs at a small extra computational cost. Our TDN presents a new state of the art on the Something-Something V1 & V2 datasets and is on par with the best performance on the Kinetics-400 dataset. In addition, we conduct in-depth ablation studies and plot the visualization results of our TDN, hopefully providing insightful analysis on temporal difference modeling. We release the code at https://github.com/MCG-NJU/TDN.

> 

## 预处理

## 概述

## 结果

## 精读

### 引文

## 摘录
