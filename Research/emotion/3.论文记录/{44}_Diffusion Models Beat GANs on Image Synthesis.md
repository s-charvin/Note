---
title: ""
author: "石昌文"
tags: [""]
description: ""
categories: [""]
keywords:  [""]
type: "笔记"
draft: true
layout: 
data: 2022-08-26 22:00:57
lastmod: 2022-08-27 16:40:46
---

# 重点

- 开源代码

# 摘要

我们证明了 diffusion 模型生成的图像样本质量可以实现优于当前最先进的生成模型。 在本研究中，我们通过一系列消融实验找到了更好的扩散模型架构，实现了无条件高质量图像合成。 此外，对于条件图像合成，我们通过分类器引导（利用分类器的梯度来权衡样本多样性和精确度）进一步提高了样本质量。 我们在 ImageNet 128×128 数据集上实现了 2.97 的 FID，在 ImageNet 256×256 上实现了 4.59 的 FID，在 ImageNet 512×512 上实现了 7.72 的 FID。并且即使每个样本只有 25 次前向传递，其图像质量依然可以匹配 BigGAN-deep，同时保持更好的分布覆盖率（多样性）。 最后，我们发现分类器引导与上采样扩散模型很好地结合在一起，在 ImageNet 256×256 上将 FID 进一步提高到了 3.94，在 ImageNet 512×512 上提高到了 3.85 的 FID。

# 结果

# 词汇记录

# 精读

在过去的几年里，生成模型已经有能力生成类人自然语言 [6]、高质量合成图像 [5, 28, 51] 和高度多样化的人类语音及音乐 [64, 13] 。这类模型有多种实现领域，如从文本提示生成图像 [72, 50] 或学习有用的特征表示 [14, 7]。虽然生成模型已经能够产生逼真的图像和声音，但在当前最先进的水平之外仍有很大的改进空间。更好的生成模型可能会对平面设计、游戏、音乐制作和无数其他领域产生广泛的影响。

GAN [19] 目前在大多数通过 FID[23]、Inception Score[54] 和 Precision [32] 等样本质量指标来衡量的图像生成任务 [5, 68, 28] 方面有非常好的表现。然而，这其中一些指标并没有完全捕捉到多样性，并且一些研究表明，GAN 网络捕捉到的多样性比先进的基于似然估计的生成模型要少 [51,43,42]。此外，GAN 网络在没有精心选择的超参数和正则化器的情况下会崩溃 [5,41,4]，难以训练。

虽然 GAN 类网络拥有非常好的性能，但它们的缺点使它们难以扩展并应用于新领域。因此，为了使用基于似然估计的模型 [51, 25, 42, 9] 实现类似 GAN 的样本质量，已经做了很多工作。虽然这些模型可以捕获更多的多样性，并且通常比 GAN 更容易扩展和训练，但它们在视觉样本质量方面仍然存在不足。此外，除了 VAE，这些模型生成样本的时间比 GAN 慢。

扩散模型是一类基于似然估计的模型，最近已被证明可以产生高质量的图像 [56,59,25]，同时保持更好的分布覆盖率（多样性）、稳定的训练目标和易于扩展等优点。这类模型通过逐渐从信号中去除噪声来生成样本，其训练目标可以表示为一个重新加权的变分下界[25]。这类模型已经在 CIFAR-10 [31] 上拥有非常优秀的表现 [60]，但是在 LSUN 和 ImageNet 等复杂的生成数据集上仍然落后于 GAN网络。 Nichol 和 Dhariwal [43] 发现这些模型会随着计算量的增加而稳定的优化，并且即使在使用上采样堆栈（upsampling stack）的 ImageNet 256×256 困难数据集上也可以产生高质量的样本。然而，该模型的 FID 仍然无法与 BigGAN-deep [5]（该数据集上当前优秀的技术）相比。

在本文中，我们假设扩散模型和 GAN 之间的差距至少源于两个因素：首先， GAN 网络文献使用的模型架构已经过大量探索和改进；其次，GANs 能够以多样性换取精准度，产生高质量的样本，但不能覆盖整个分布。因此我们的目标就是为扩散模型优化这两个问题，首先是通过改进模型架构，然后设计一个方案来权衡多样性和精准度。通过这些改进，我们在几个不同的指标和数据集上超越了 GAN。

本文的其余部分安排如下。在第 2 节中，我们简要介绍了 Ho 等人提出的扩散模型[25] 以及 Nichol 、Dhariwal [43] 、 Song [57]等人的改进，并且我们还描述了本研究中的评估设置。在第 3 节中，我们介绍了简单的架构改进，这些改进极大地提高了FID 指标。在第 4 节中，我们描述了一种在采样期间，使用分类器梯度指导扩散模型的方法。我们发现调整单个超参数，即分类器梯度的尺度，就可以权衡多样性和精准度，并且我们可以将这个梯度尺度因子增加一个数量级，而无需获得对抗样本 [61]。最后，在第 5 节中，我们展示了经过我们改进的模型架构，在无条件图像合成任务和在分类器指导下的条件图像合成上展现的优秀表现。当使用分类器指导时，我们发现我们可以使用少至 25 次前向传递进行采样，同时保持与 BigGAN 相当的 FID 指标。我们还将我们改进的模型与上采样堆栈进行了比较，发现这两种方法提供了互补的改进，并且将它们结合起来可以在 ImageNet 256×256 和 512×512 上获得最佳结果。

背景

在本节中，我们对扩散模型进行了简要概述。 有关更详细的数学描述，我们请读者参阅附录 B。

更高层次的，扩散模型通过扭转逐步添加噪声的过程，从分布中采样。 特别的，采样过程会从噪声 x T 开始，并逐渐产生噪声较小的样本 x T-1、x T-2、...，直到达到最终样本 x0。 每个时间步长 t 对应于某个噪声水平，xt 可以被认为是信号 x0 与一些噪声的混合，其中信噪比由时间步长 t 确定。 对于本文的其余部分，我们假设噪声是从对角高斯分布（diagonal Gaussian distribution）中提取的，这对于自然图像很有效，并且简化了各种推导。

扩散模型会学习从 xt 产生稍微“去噪”的 xt-1。 何[25] 将此模型参数化为一个函数 θ(xt,t)，它能够预测噪声样本 xt 的噪声分量。 为了训练这些模型，小批量中的每个样本都是通过随机抽取数据样本 x0、时间步长 t 和噪声ε来产生的，它们共同产生噪声样本 xt（等式 17）。 那么训练目标是||θ(xt, t) -ε || ，即真实噪声和预测噪声之间的简单均方误差损失（等式 26）。

如何从噪声预测器 θ(xt, t) 中采样并不是很明显。 回想一下，扩散采样是通过从 xt 开始重复预测 xt−1 进行的，从 xT 开始。 [25] 表明，在合理的假设下，我们可以将给定 xt 的 xt-1 的分布 pθ(xt-1|xt) 建模为对角高斯噪声 N (xt-1; µθ(xt, t), Σθ(xt, t))，其中平均 µθ(xt, t) 可以计算为 θ(xt, t) 的函数（公式 27）。 该高斯分布的方差 Σθ(xt, t) 可以固定为已知常数 [25] 或使用单独的神经网络头 [43] 学习，当扩散步骤总数为 T 足够大时，这两种方法都会产生高质量的样本。

[25] 观察到，简单的均方误差目标 Lsimple 在实践中比实际变分下界 Lvlb 效果更好，后者可以通过将去噪扩散模型解释为 VAE 得出。 他们还注意到，使用此目标进行训练并使用相应的采样程序相当于 Song 和 Ermon [58] 的去噪分数匹配模型，他们使用 Langevin 动力学从经过多个噪声级别训练的去噪模型中进行采样，以产生高质量的图像样品。 我们经常使用“扩散模型”作为简写来指代这两类模型。

改进

继 Song 和 Ermon [58] 以及 Ho [25]的突破性工作之后，最近的几篇论文提出了对扩散模型的改进。 在这里，我们描述了其中一些改进，我们将其用于我们的模型。

Nichol 和 Dhariwal [43] 发现将方差 Σθ(xt, t) 固定为常数，如 Ho [25] 等人所做的那样。 对于具有较少扩散步骤的采样是次优的，并建议将 Σθ(xt, t) 参数化为一个神经网络，其输出 v 被插值为：

这里，βt 和 β~t（等式 19）是 Ho [25] 等人的方差。 对应于逆过程方差的上限和下限。 此外，Nichol 和 Dhariwal [43] 提出了一个混合目标，用于使用加权和 Lsimple + λLvlb 来训练 θ(xt, t) 和 Σθ(xt, t)。 用他们的混合目标学习逆向过程方差，可以用更少的步骤进行采样，而不会大幅降低样本质量。 我们采用这个目标和参数化，并在我们的整个实验中使用它。

宋 [57] 提出了 DDIM，它制定了一种替代的非马尔可夫噪声过程，该过程具有与 DDPM 相同的前向边际，但允许通过改变反向噪声的方差来产生不同的反向采样器。 通过将此噪声设置为 0，他们提供了一种将任何模型 θ(xt, t) 转换为从潜在图像到图像的确定性映射的方法，并发现这提供了一种以更少步骤进行采样的替代方法。 当使用少于 50 个采样步骤时，我们采用这种采样方法，因为 Nichol 和 Dhariwal [43] 发现它在这种情况下是有益的。

## 样本质量指标

为了比较模型之间的样本质量，我们使用以下指标进行定量评估。 虽然这些指标在实践中经常使用并且与人类判断非常吻合，但它们并不是完美的代表，为样本质量评估寻找更好的指标仍然是一个悬而未决的问题。

初始分数 (IS) 由 Salimans 等人提出。 [54]，它衡量了模型在捕获完整 ImageNet 类分布的同时仍然产生令人信服的单个类示例的单个样本的能力。该指标的一个缺点是它不会奖励覆盖整个分布或捕获类内的多样性，并且记住完整数据集的一小部分子集的模型仍然具有高 IS [3]。为了比 IS 更好地捕捉多样性，Heusel 等人提出了 Fréchet 初始距离 (FID)。 [23]，他认为它比初始分数更符合人类判断。 FID 提供了 Inception-V3 [62] 潜在空间中两个图像分布之间距离的对称度量。最近，sFID 由 Nash 等人提出。 [42] 作为 FID 的一个版本，它使用空间特征而不是标准的池化特征。他们发现该指标更好地捕捉空间关系，奖励具有连贯高级结构的图像分布。最后，Kynkäänniemi 等人。 [32]提出了改进的精度和召回指标，分别衡量样本保真度作为模型样本落入数据流形的比例（精度），多样性作为数据样本落入样本流形的比例（召回）。

我们使用 FID 作为整体样本质量比较的默认指标，因为它同时捕获了多样性和保真度，并且一直是最先进的生成建模工作的事实上的标准指标 [27、28、5、25]。我们使用 Precision 或 IS 来衡量保真度，并使用 Recall 来衡量多样性或分布覆盖率。在与其他方法进行比较时，我们会尽可能使用公共样本或模型重新计算这些指标。这有两个原因：首先，一些论文 [27, 28, 25] 与训练集的任意子集进行比较，这些子集不容易获得；其次，细微的实现差异会影响最终的 FID 值 [45]。为了确保一致的比较，我们使用整个训练集作为参考批次 [23, 5]，并使用相同的代码库评估所有模型的指标。

结构改进

在本节中，我们进行了几次架构消融，以找到为扩散模型提供最佳样本质量的模型架构。何 [25] 介绍了用于扩散模型的 UNet 架构，Jolicoeur-Martineau [26] 发现与以前用于去噪分数匹配的架构 [58, 33] 相比，它显着提高了样本质量。 UNet 模型使用一堆残差层和下采样卷积，然后是一堆带有上采样卷积的残差层，使用跳跃连接连接具有相同空间大小的层。此外，他们使用单头的 16×16 分辨率的全局注意力层，并将时间步嵌入的投影添加到每个残差块中。宋 [60] 发现对 UNet 架构的进一步更改提高了 CIFAR-10 [31] 和 CelebA-64 [34] 数据集的性能。我们在 ImageNet 128×128 上展示了相同的结果，发现架构确实可以在更大、更多样化的数据集上以更高分辨率显着提高样本质量。我们探索以下架构变化：

- 增加深度与宽度，保持模型尺寸相对恒定。
- 增加注意力头的数量。
- 在 32×32、16×16 和 8×8 分辨率而不是仅在 16×16 分辨率下使用注意力。
- 按照[60]，使用BigGAN [5] 残差块对激活进行上采样和下采样。
- 使用 √ 1 2 重新缩放残差连接，遵循 [60, 27, 28]

对于本节中的所有比较，我们在 ImageNet 128×128 上训练模型，批量大小为 256，并使用 250 个采样步骤进行采样。 我们训练具有上述架构变化的模型并比较等。 [25] 使 FID 变得更糟。 它们在 FID 上，在两个不同的训练点进行评估，如表 1 所示。除了重新调整残差连接之外，所有其他修改都提高了性能并具有积极的复合效果。 我们在图 2 中观察到，虽然增加深度有助于提高性能，但它会增加训练时间并且需要更长的时间才能达到与更广泛模型相同的性能，因此我们选择不在进一步的实验中使用这种变化。

我们还研究了其他更匹配 Transformer 架构的注意力配置 [66]。 为此，我们尝试将注意力头固定为常数，或固定每个头的通道数。 对于架构的其余部分，我们使用 128 个基本通道、每个分辨率 2 个残差块、多分辨率注意力和 BigGAN 上/下采样，我们训练模型进行 70 万次迭代。 表 2 显示了我们的结果，表明更多的磁头或更少的每个磁头通道可以提高 FID。 在图 2 中，我们看到 64 通道最适合挂钟时间，因此我们选择使用每头 64 通道作为我们的默认值。 我们注意到，这种选择也更好地匹配现代变压器架构，并且在最终 FID 方面与我们的其他配置相当。

自适应组归一化

我们还试验了一个层 [43]，我们称之为自适应组归一化 (AdaGN)，它在组归一化操作 [69] 后将时间步长和类嵌入到每个残差块中，类似于自适应实例范数 [27] 和 电影[48]。 我们将这一层定义为 AdaGN(h, y) = ys GroupNorm(h)+yb，其中 h 是第一个卷积之后残差块的中间激活，y = [ys, yb] 是从 时间步长和类嵌入。

我们已经看到 AdaGN 改进了我们最早的扩散模型，因此默认情况下它包含在我们所有的运行中。 在表 3 中，我们明确地消除了这种选择，并发现自适应组归一化层确实改善了 FID。 两种模型每个分辨率使用 128 个基本通道和 2 个残差块，每个头部 64 个通道的多分辨率注意力，以及 BigGAN 上/下采样，并经过 70 万次迭代训练。

在本文的其余部分，我们使用这个最终改进的模型架构作为我们的默认值：可变宽度，每个分辨率有 2 个残差块，多头，每个头有 64 个通道，注意力在 32、16 和 8 分辨率，BigGAN 残差块用于向上和 下采样和自适应组归一化，用于将时间步长和类嵌入注入残差块。

分类器指导

除了采用精心设计的架构外，用于条件图像合成的 GAN [39, 5] 还大量使用类标签。 这通常采用类条件归一化统计 [16, 11] 的形式，以及具有明确设计为类似于分类器 p(y|x) [40] 的头部的判别器。 作为进一步证明类信息对这些模型的成功至关重要的证据，Lucic 等人。 [36] 发现在标签受限的情况下生成合成标签很有帮助。

鉴于对 GAN 的这种观察，探索不同的方法来调节类标签上的扩散模型是有意义的。 我们已经将类信息合并到规范化层中（第 3.1 节）。 在这里，我们探索了一种不同的方法：利用分类器 p(y|x) 来改进扩散生成器。 Sohl-Dickstein 等人。 [56]和宋等人。 [60] 展示了实现此目的的一种方法，其中可以使用分类器的梯度来调节预训练的扩散模型。 特别是，我们可以在噪声图像 xt 上训练分类器 pφ(y|xt, t)，然后使用梯度 ∇xt log pφ(y|xt, t) 引导扩散采样过程朝向任意类标签 y。

在本节中，我们首先回顾使用分类器推导条件采样过程的两种方法。 然后我们描述了我们如何在实践中使用这些分类器来提高样本质量。 为简洁起见，我们选择符号 pφ(y|xt, t) = pφ(y|xt) 和 θ(xt, t) = θ(xt)，注意它们指的是每个时间步长 t 和训练时的单独函数 时间模型必须以输入 t 为条件。

条件反向噪声过程

我们从具有无条件反向噪声过程 pθ(xt|xt+1) 的扩散模型开始。 为了以标签 y 为条件，只需根据

其中 Z 是归一化常数（附录 H 中的证明）。 通常很难从这个分布中准确地采样，但是 Sohl-Dickstein 等人。 [56]表明它可以近似为扰动高斯分布。 在这里，我们回顾一下这个推导。

回想一下，我们的扩散模型使用高斯分布从时间步 xt+1 预测前一个时间步 xt：

我们可以假设 logφ p(y|xt) 与 Σ -1 相比具有低曲率。 这个假设在无限扩散步的限制下是合理的，其中 ||Σ|| → 0。在这种情况下，我们可以使用围绕 xt = µ 的泰勒展开来近似 log pφ(y|xt) 为

我们可以放心地忽略常数项 C4，因为它对应于等式 2 中的归一化系数 Z。因此，我们发现条件转移算子可以用类似于无条件转移算子的高斯近似，但其均值偏移了 Σg . 算法 1 总结了相应的采样算法。 我们为梯度包含了一个可选的比例因子 s，我们将在 4.3 节中更详细地描述它。

Conditional Sampling for DDIM

上述条件采样推导仅适用于随机扩散采样过程，不能应用于DDIM等确定性采样方法[57]。 为此，我们使用了从 Song 等人改编的基于分数的调节技巧。 [60]，它利用了扩散模型和分数匹配之间的联系[59]。 特别是，如果我们有一个模型 θ(xt) 可以预测添加到样本中的噪声，那么这可以用来推导得分函数：

我们现在可以将其代入 p(xt)p(y|xt) 的得分函数：

最后，我们可以定义一个新的 epsilon 预测 ^(xt)，它对应于联合分布的分数：

然后我们可以使用与常规 DDIM 完全相同的采样程序，但使用修改后的噪声预测 ^θ(xt) 而不是 θ(xt)。 算法 2 总结了相应的采样算法。

缩放分类器梯度

为了将分类器引导应用于大规模生成任务，我们在 ImageNet 上训练分类模型。 我们的分类器架构只是 UNet 模型的下采样主干，在 8x8 层有一个注意力池 [49] 以产生最终输出。 我们在与相应扩散模型相同的噪声分布上训练这些分类器，并添加随机裁剪以减少过度拟合。 训练后，我们使用公式 10 将分类器纳入扩散模型的采样过程，如算法 1 所述。

在无条件 ImageNet 模型的初始实验中，我们发现有必要将分类器梯度缩放一个大于 1 的常数因子。当使用 1 的比例时，我们观察到分类器为所需的类分配了合理的概率（大约 50%）最终样品，但这些样品在目视检查时与预期类别不匹配。扩大分类器梯度解决了这个问题，分类器的分类概率增加到接近 100%。图 3 显示了这种效果的一个示例。

要了解缩放分类器梯度的效果，请注意 s · ∇x log p(y|x) = ∇x log 1 Z p(y|x) s ，其中 Z 是任意常数。因此，调节过程在理论上仍然基于与 p(y|x) s 成比例的重新归一化分类器分布。当 s > 1 时，该分布变得比 p(y|x) 更尖锐，因为较大的值会被指数放大。换句话说，使用更大的梯度尺度更多地关注分类器的模式，这对于产生更高保真度（但多样性较低）的样本可能是可取的。

在上述推导中，我们假设基础扩散模型是无条件的，建模 p(x)。也可以训练条件扩散模型 p(x|y)，并以完全相同的方式使用分类器引导。表 4 表明，无条件模型和条件模型的样本质量都可以通过分类器引导大大提高。我们看到，在足够高的规模下，引导无条件模型可以非常接近无引导条件模型的 FID，尽管直接使用类标签进行训练仍然有帮助。引导条件模型进一步改进 FID。

表 4 还显示，分类器引导以召回为代价提高了精度，因此在样本保真度与多样性之间进行了权衡。我们明确评估了这种权衡如何随 1.0 变化]。图 4 中的梯度比例。我们看到，将梯度缩放到 1.0 以上可以平滑地权衡召回率（多样性的度量）以获得更高的精度和 IS（保真度的度量）。由于 FID 和 sFID 依赖于多样性和保真度，它们的最佳值是在中间点获得的。我们还将我们的指导与图 5 中 BigGAN 的截断技巧进行了比较。我们发现，在 FID 与 Inception Score 之间进行权衡时，分类器指导严格优于 BigGAN-deep。不太明确的是精度/召回率的权衡，这表明分类器引导只有在一定的精度阈值之前才是更好的选择，在此之后它不能达到更好的精度。

结果

为了评估我们改进的无条件图像生成模型架构，我们在三个 LSUN [71] 类上训练单独的扩散模型：卧室、马和猫。为了评估分类器指导，我们在 ImageNet [52] 数据集上以 128×128、256×256 和 512×512 的分辨率训练条件扩散模型。

表 5 总结了我们的结果。我们的扩散模型可以在每项任务上获得最佳 FID，在除一项任务之外的所有任务上获得最佳 sFID。通过改进的架构，我们已经在 LSUN 和 ImageNet 64×64 上获得了最先进的图像生成。对于更高分辨率的 ImageNet，我们观察到分类器引导使我们的模型大大优于最好的 GAN。这些模型获得类似于 GAN 的感知质量，同时保持更高的分布覆盖率（通过召回率测量），甚至可以仅使用 25 个扩散步骤来实现。

图 6 将来自最佳 BigGAN 深度模型的随机样本与我们的最佳扩散模型进行了比较。虽然样本具有相似的感知质量，但扩散模型包含比 GAN 更多的模式，例如缩放的鸵鸟头、单个火烈鸟、不同方向的芝士汉堡，以及没有人拿着它的 tinca 鱼。我们还在附录 C 中检查了我们在 Inception-V3 特征空间中生成的最近邻样本，并在附录 K-M 中展示了其他样本。

我们还将指导与使用两阶段上采样堆栈进行了比较。 Nichol 和 Dhariwal [43] 和 Saharia 等人。 [53]通过将低分辨率扩散模型与相应的上采样扩散模型相结合来训练两阶段扩散模型。在这种方法中，上采样模型被训练以从训练集中对图像进行上采样，并使用简单的插值（例如双线性）将低分辨率图像的条件连接到模型输入的通道上。在采样过程中，低分辨率模型产生一个样本，然后上采样模型以此样本为条件。这极大地提高了 ImageNet 256×256 上的 FID，但没有达到与 BigGAN-deep [43, 53] 等最先进模型相同的性能，如表 5 所示。

在表 6 中，我们展示了引导和上采样提高了不同轴上的样本质量。虽然上采样在保持高召回率的同时提高了精度，但指导提供了一个旋钮来权衡多样性以获得更高的精度。我们通过在上采样到更高分辨率之前使用较低分辨率的指导来实现最佳 FID，这表明这些方法相互补充。

# 引文
