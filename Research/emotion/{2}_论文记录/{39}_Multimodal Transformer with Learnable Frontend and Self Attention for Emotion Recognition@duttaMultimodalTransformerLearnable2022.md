---
title: "Multimodal Transformer with Learnable Frontend and Self Attention for Emotion Recognition"
description: ""
citekey: duttaMultimodalTransformerLearnable2022
author: "石昌文"
tags: [""]
categories: "PaperNote"
keywords:  [""]
draft: true
layout: "blog"
---

> [!info] 论文信息
>1. Title：Multimodal Transformer with Learnable Frontend and Self Attention for Emotion Recognition
>2. Author：Soumya Dutta, Sriram Ganapathy
>3. Entry：[Zotero link](zotero://select/items/@duttaMultimodalTransformerLearnable2022) [URL link]() [PDF link](<file:///C\:\\Users\\19115\\OneDrive - stu.suda.edu.cn\\Zotero\\Dutta_Ganapathy_2022_Multimodal Transformer with Learnable Frontend and Self Attention for Emotion.pdf>)
>4. Other：2022 - ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)     -   

>- :luc_github: 论文实现：
>- :luc_external_link: 论文解读：
>- :luc_linkedin: 相关笔记：***


## ⭐ 重点

- 

## 摘要

> [!abstract] In this work, we propose a novel approach for multi-modal emotion recognition from conversations using speech and text. The audio representations are learned jointly with a learnable audio front-end (LEAF) model feeding to a CNN based classifier. The text representations are derived from pre-trained bidirectional encoder representations from transformer (BERT) along with a gated recurrent network (GRU). Both the textual and audio representations are separately processed using a bidirectional GRU network with self-attention. Further, the multi-modal information extraction is achieved using a transformer that is input with the textual and audio embeddings at the utterance level. The experiments are performed on the IEMOCAP database, where we show that the proposed framework improves over the current state-of-the-art results under all the common test settings. This is primarily due to the improved emotion recognition performance achieved in the audio domain. Further, we also show that the model is more robust to textual errors caused by an automatic speech recognition (ASR) system.

> 

## 预处理

## 概述

## 结果

## 精读

### 引文

## 摘录
