---
title: ""
author: "çŸ³æ˜Œæ–‡"
tags: [""]
description: ""
categories: [""]
keywords:  [""]
type: ""
draft: true
layout: 
data: 2021-12-07 11:06:55
lastmod: 2022-03-29 13:41:05
---

# å®‰è£…

å®‰è£…ğŸ¤—Transformersï¼Œå¹¶è®¾ç½®cache,ä»¥åŠå°†ğŸ¤—Transformersé…ç½®ä¸ºè„±æœºè¿è¡Œã€‚

å®˜æ–¹æµ‹è¯•ç¯å¢ƒ: Python3.6+ã€PyTorch 1.1.0+ã€TensorFlow 2.0+å’ŒFlax

- [PyTorch](https://pytorch.org/get-started/locally/) å®‰è£…æ•™ç¨‹.
- [TensorFlow 2.0](https://www.tensorflow.org/install/pip) å®‰è£…æ•™ç¨‹.
- [Flax](https://flax.readthedocs.io/en/latest/) å®‰è£…æ•™ç¨‹.

## ä½¿ç”¨ conda å®‰è£…

ä½¿ç”¨condaå®‰è£… `huggingface`:

```shell
conda install -c huggingface transformers
```

## ä½¿ç”¨ pip è¿›è¡Œå®‰è£…

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£… ğŸ¤— Transformersï¼š

```shell
pip install transformers
```

å¯¹äºä»…æ”¯æŒCPUçš„ç³»ç»Ÿï¼Œæ‚¨å¯ä»¥ä»…ä½¿ç”¨ä¸€è¡Œå‘½ä»¤æ–¹ä¾¿åœ°å®‰è£…ğŸ¤—Transformers å’Œæ·±åº¦å­¦ä¹ åº“ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…ğŸ¤—Transformerså’ŒPyTorchï¼š

```shell
pip install transformers[torch]
```

å®‰è£…ğŸ¤—  Transformers å’Œ TensorFlow 2.0ï¼š

```shell
pip install transformers[tf-cpu]
```

å®‰è£…ğŸ¤— Transformers and Flaxï¼š

```shell
pip install transformers[flax]
```

æœ€åï¼Œé€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ£€æŸ¥æ˜¯å¦æ­£ç¡®å®‰è£…äº†ğŸ¤—Transformersï¼Œå®ƒå°†ä¸‹è½½ä¸€ä¸ªé¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹ï¼š

```shell
python -c "from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))"
```

ç„¶åæ‰“å°å‡º`label`å’Œ`score`ï¼š

```shell
[{'label': 'POSITIVE', 'score': 0.9998704791069031}]
```

## ä»æºæ–‡ä»¶å®‰è£…

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä»æºæ–‡ä»¶å®‰è£… ğŸ¤— Transformersï¼š

```shell
pip install git+https://github.com/huggingface/transformers
```

æ­¤å‘½ä»¤å®‰è£…çš„æ˜¯æœ€æ–°å¼€å‘çš„ `master` ç‰ˆæœ¬è€Œä¸æ˜¯ `stable` ç‰ˆæœ¬ã€‚ `master` ç‰ˆæœ¬å¯¹äºäº†è§£æœ€æ–°è¿›å±•éå¸¸æœ‰ç”¨ã€‚ 

é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ£€æŸ¥æ˜¯å¦æ­£ç¡®å®‰è£…äº†ğŸ¤—Transformersï¼š

```shell
python -c "from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))"
```

## Editable å®‰è£…

å¦‚æœéœ€è¦æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼Œåˆ™ä½¿ç”¨ Editable å®‰è£…ï¼š

- ä½¿ç”¨æºç çš„ `master` ç‰ˆæœ¬ã€‚
- ä¸º ğŸ¤— Transformers åšå‡ºè´¡çŒ®ï¼Œå¹¶æµ‹è¯•ä»£ç ä¸­çš„æ›´æ”¹ã€‚

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å…‹éš†å­˜å‚¨åº“å¹¶å®‰è£… ğŸ¤— Transformersï¼š

```shell
git clone https://github.com/huggingface/transformers.git
cd transformers
pip install -e .
```

æ­¤å‘½ä»¤å°†é“¾æ¥å½“å‰å…‹éš†çš„å­˜å‚¨åº“æ–‡ä»¶å¤¹å’ŒPythonåº“è·¯å¾„ã€‚ç°åœ¨ï¼Œé™¤äº†å¸¸è§„Pythonåº“è·¯å¾„ä¹‹å¤–ï¼ŒPythonè¿˜å°†æŸ¥çœ‹å½“å‰å…‹éš†çš„æ–‡ä»¶å¤¹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨çš„PythonåŒ…é€šå¸¸å®‰è£…åœ¨ `~/anaconda3/envs/main/lib/python3.7/site-packages/`, Pythonè¿˜å°†æœç´¢å½“å‰å…‹éš†çš„æ–‡ä»¶å¤¹ï¼š`~/transformers/`.

å¦‚æœæ‚¨æƒ³ç»§ç»­ä½¿ç”¨åº“ï¼Œåˆ™å¿…é¡»ä¿ç•™`Transformers`æ–‡ä»¶å¤¹ã€‚

ç°åœ¨ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è½»æ¾åœ°å°†å…‹éš†åº“æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬çš„ğŸ¤—Transformersï¼š

```shell
cd ~/transformers/
git pull
```

## ç¼“å†²è®¾ç½®

ç›®å‰å¦‚æœä¸‹è½½é¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæ¨¡å‹å°†ç¼“å­˜åœ¨ä»¥ä¸‹ä½ç½®ï¼š`~/.cache/huggingFaces/Transers/`ï¼Œæ­¤ä½ç½®ç”±shell ç¯å¢ƒå˜é‡ä¸­çš„ TRANSFORMERS_CACHE 
 å†³å®šã€‚åœ¨Windowsä¸Šï¼Œé»˜è®¤ç›®å½•ä¸º`C:\Users\username\.cache\huggingface\transformers`ã€‚å¯ä»¥æŒ‰ä¼˜å…ˆçº§é¡ºåºæ›´æ”¹å¦‚ä¸‹æ‰€ç¤ºçš„shell ç¯å¢ƒå˜é‡ï¼Œä»¥æŒ‡å®šä¸åŒçš„ç¼“å­˜ç›®å½•ï¼š

1. Shell environment variable (default): `TRANSFORMERS_CACHE`.
2. Shell environment variable: `HF_HOME` + `transformers/`.
3. Shell environment variable: `XDG_CACHE_HOME` + `/huggingface/transformers`.

å¦‚æœä½¿ç”¨è¿‡è¯¥åº“çš„æ—©æœŸç‰ˆæœ¬å¹¶è®¾ç½®è¿‡ç›¸åº”çš„ç¯å¢ƒå˜é‡ï¼Œåˆ™é™¤éæŒ‡å®šäº† Shell ç¯å¢ƒå˜é‡ `TRANSFORMERS_CACHE`ï¼ŒğŸ¤— Transformers å°†ä½¿ç”¨ shell ç¯å¢ƒå˜é‡`PYTORCH_TRANSFORMERS_CACHE` æˆ– `PYTORCH_PRETRAINED_BERT_CACHE` ã€‚

## ç¦»çº¿æ¨¡å¼

 åªéœ€ä½¿ç”¨æœ¬åœ°æ–‡ä»¶ï¼ŒğŸ¤—Transformers å°±å¯ä»¥åœ¨ç¦»çº¿ç¯å¢ƒä¸­è¿è¡Œã€‚è®¾ç½®ç¯å¢ƒå˜é‡`TRANSFORMERS_OFFLINE=1=1`ä»¥å¯ç”¨æ­¤è¡Œä¸ºã€‚

é€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡ `HF_DATASETS_OFFLINE=1`ï¼Œå¯ä»¥å°† [ğŸ¤— Datasets](https://huggingface.co/docs/datasets/) æ·»åŠ åˆ°ç¦»çº¿è®­ç»ƒå·¥ä½œæµç¨‹ä¸­ã€‚

ä¾‹å¦‚ï¼Œé€šå¸¸ä¼šä½¿ç”¨ä»¥ä¸‹å‘½ä»¤åœ¨æœ‰ç½‘ç»œæƒ…å†µä¸‹è¿è¡Œå®ä¾‹ç¨‹åºï¼š

```
python examples/pytorch/translation/run_translation.py --model_name_or_path t5-small --dataset_name wmt16 --dataset_config ro-en ...
```

ä½†æ˜¯ä¹Ÿå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤åœ¨ç¦»çº¿æƒ…å†µä¸‹ä¸­è¿è¡Œç›¸åŒçš„ç¨‹åºï¼š

```
HF_DATASETS_OFFLINE=1 TRANSFORMERS_OFFLINE=1 \
python examples/pytorch/translation/run_translation.py --model_name_or_path t5-small --dataset_name wmt16 --dataset_config ro-en ...
```

### è·å–è¦è„±æœºä½¿ç”¨çš„ models å’Œtokenizers 

å¦ä¸€ä¸ªç¦»çº¿ä½¿ç”¨ ğŸ¤— Transformers çš„ä¸€ä¸ªæ–¹æ³•æ˜¯æå‰ä¸‹è½½å¥½æ–‡ä»¶ï¼Œç„¶ååœ¨éœ€è¦è„±æœºä½¿ç”¨å®ƒä»¬æ—¶æŒ‡å‘å®ƒä»¬çš„æœ¬åœ°è·¯å¾„ã€‚æœ‰å¦‚ä¸‹ä¸‰ç§å®ç°é€”å¾„:

- ç‚¹å‡»â†“å›¾æ ‡ï¼Œåœ¨[Model Hub](https://huggingface.co/models)çš„ç”¨æˆ·ç•Œé¢ä¸‹è½½æ–‡ä»¶ã€‚

![download-icon](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/download-icon.png)

- ä½¿ç”¨ [PreTrainedModel.from_pretrained()](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) å’Œ [PreTrainedModel.save_pretrained()](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained) å·¥ä½œæµç¨‹:

  1. ä½¿ç”¨[PreTrainedModel.from_pretrained()](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained)æå‰ä¸‹è½½å¥½æ–‡ä»¶ï¼š
		```python
		from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
		tokenizer = AutoTokenizer.from_pretrained("bigscience/T0_3B")
		model = AutoModelForSeq2SeqLM.from_pretrained("bigscience/T0_3B")
		```

  2. ä½¿ç”¨ [PreTrainedModel.save_pretrained()](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/model#transformers.PreTrainedModel.save_pretrained)ä¿å­˜æ–‡ä»¶åˆ°æŒ‡å®šç›®å½•
		```python
		tokenizer.save_pretrained("./your/path/bigscience_t0")
		model.save_pretrained("./your/path/bigscience_t0")
		```

  3. å½“å¤„äºç¦»çº¿çŠ¶æ€æ—¶ï¼Œä½¿ç”¨[PreTrainedModel.from_pretrained()](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/model#transformers.PreTrainedModel.from_pretrained) ä»æŒ‡å®šç›®å½•åŠ è½½æ–‡ä»¶ï¼š
		```python
		tokenizer = AutoTokenizer.from_pretrained("./your/path/bigscience_t0")
		model = AutoModel.from_pretrained("./your/path/bigscience_t0")
		```

- ä½¿ç”¨[huggingface_hub](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub)åº“ä»¥ç¼–ç¨‹æ–¹å¼ä¸‹è½½æ–‡ä»¶ï¼š

	1. å®‰è£… `huggingface_hub` åº“ ï¼š

		```python
		python -m pip install huggingface_hub
		```

	2. ä½¿ç”¨ [`hf_hub_download`](https://huggingface.co/docs/hub/adding-a-library#download-files-from-the-hub) ä¸‹è½½æ–‡ä»¶åˆ°æŒ‡å®šè·¯å¾„ã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹å‘½ä»¤å°†`config.json`æ–‡ä»¶ä»[T0](https://huggingface.co/bigscience/T0_3B)æ¨¡å‹ä¸‹è½½åˆ°æ‚¨æ‰€éœ€çš„è·¯å¾„ï¼š

		```python
		from huggingface_hub import hf_hub_download	
		hf_hub_download(repo_id="bigscience/T0_3B", filename="config.json", cache_dir="./your/path/bigscience_t0")
		```

	3. ä¸‹è½½æ–‡ä»¶å¹¶åœ¨æœ¬åœ°ç¼“å­˜åï¼ŒæŒ‡å®šè¦åŠ è½½å’Œä½¿ç”¨çš„æœ¬åœ°è·¯å¾„ï¼š

		```python
		from transformers import AutoConfig
		
		config = AutoConfig.from_pretrained("./your/path/bigscience_t0/config.json")
		```

æœ‰å…³ä¸‹è½½å­˜å‚¨åœ¨ä¸­å¿ƒä¸Šçš„æ–‡ä»¶çš„æ›´å¤šä¿¡æ¯ï¼Œå¯ä»¥å‚é˜…[å¦‚ä½•ä»ä¸­å¿ƒä¸‹è½½æ–‡ä»¶](https://huggingface.co/docs/hub/how-to-downstream)ã€‚
