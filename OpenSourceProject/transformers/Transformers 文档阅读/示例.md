---
title: ""
author: "石昌文"
tags: [""]
description: ""
categories: [""]
keywords:  [""]
type: ""
draft: true
layout: 
data: 2022-04-01 09:54:38
lastmod: 2022-04-01 11:08:50
---

# pipeline

```python
transformers.pipeline( 
	task: str = None, model: typing.Optional = None, 
	config: typing.Union[str, transformers.configuration_utils.PretrainedConfig, NoneType] = None,
	tokenizer: typing.Union[str, transformers.tokenization_utils.PreTrainedTokenizer, NoneType] = None,
	feature_extractor: typing.Union[str, ForwardRef('SequenceFeatureExtractor'), NoneType] = None, 
	framework: typing.Optional[str] = None, 
	revision: typing.Optional[str] = None, 
	use_fast: bool = True, 
	use_auth_token: typing.Union[str, bool, NoneType] = None, 
	model_kwargs: typing.Dict[str, typing.Any] = None, 
	pipeline_class: typing.Optional[typing.Any] = None, 
	**kwargs ) → Pipeline

```



输入参数：

**task** (`str`) — 定义pipeline要执行的任务：

- `"audio-classification"`: 语音分类，返回一个 [AudioClassificationPipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.AudioClassificationPipeline)。
- `"automatic-speech-recognition"`: 自动语音识别，返回一个 [AutomaticSpeechRecognitionPipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline)。

- `"conversational"`: 对话生成，返回一个  [ConversationalPipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.ConversationalPipeline)。

- `"feature-extraction"`: 特征提取，返回一个 [FeatureExtractionPipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.FeatureExtractionPipeline)。

- `"fill-mask"`: ，返回一个  [FillMaskPipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.FillMaskPipeline)。

- `"image-classification"`: 图片分类，返回一个 [ImageClassificationPipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.ImageClassificationPipeline)。

- `"question-answering"`: 问答，返回一个 [QuestionAnsweringPipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.QuestionAnsweringPipeline)。
- `"table-question-answering"`: ，返回一个 [TableQuestionAnsweringPipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.TableQuestionAnsweringPipeline)。

- `"text2text-generation"`: ，返回一个 [Text2TextGenerationPipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.Text2TextGenerationPipeline)。

- `"text-classification"` (alias `"sentiment-analysis"` available): ，返回一个  [TextClassificationPipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.TextClassificationPipeline)。

- `"text-generation"`: ，返回一个  [TextGenerationPipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.TextGenerationPipeline)。

- `"token-classification"` (alias `"ner"` available): ，返回一个 [TokenClassificationPipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.TokenClassificationPipeline)。
- `"translation"`: ，返回一个  [TranslationPipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.TranslationPipeline)。

- `"translation_xx_to_yy"`: ，返回一个 [TranslationPipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.TranslationPipeline)。

- `"summarization"`: ，返回一个  [SummarizationPipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.SummarizationPipeline).
- `"zero-shot-classification"`: ，返回一个 [ZeroShotClassificationPipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.ZeroShotClassificationPipeline)。

**model** (`str` or [PreTrainedModel](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/model#transformers.PreTrainedModel) or [TFPreTrainedModel](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/model#transformers.TFPreTrainedModel), *optional*) — pipeline要使用的模型结构，输入模型名称或者继承自 [PreTrainedModel](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/model#transformers.PreTrainedModel) (for PyTorch) 和 [TFPreTrainedModel](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/model#transformers.TFPreTrainedModel) (for TensorFlow)的模型。

**config** (`str` or [PretrainedConfig](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/configuration#transformers.PretrainedConfig), *optional*) — pipeline中用来实例化模型的参数配置，输入可以是参数文件名称或者继承自[PretrainedConfig](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/configuration#transformers.PretrainedConfig)的类。

**tokenizer** (`str` or [PreTrainedTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizer), *optional*) — pipeline中为模型编码输入数据的tokenizer(分词器)，输入可以是参数文件名称或者继承自[PreTrainedTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)的类，也可以在config里面设置。

**feature_extractor** (`str` or `PreTrainedFeatureExtractor`, *optional*) — pipeline中为模型编码输入数据的特征提取器，用于非NLP的任务（语音、视觉、多模态任务），输入可以是参数文件名称或者继承自`PreTrainedFeatureExtractor`的类，也可以在config里面设置。

**framework** (`str`, *optional*) — 设置模型架构基础， `"pt"` 为PyTorch ， `"tf"` 为 TensorFlow。

**revision** (`str`, *optional*, defaults to `"main"`) — 指定要使用的模型版本，可以是branch，tag或commit id等 git 使用的标识符。

**use_fast** (`bool`, *optional*, defaults to `True`) — 是否使用Fast tokenizer ( [PreTrainedTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)).

**use_auth_token** (`str` or *bool*, *optional*) —用作远程文件HTTP bearer 协议授权的 token。

Returns：[Pipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.Pipeline)

```python
from transformers import pipeline
from transformers.pipelines.pt_utils import KeyDataset

pipe = pipeline(
	task="text-generation",
    model=model, 
    tokenizer=tokenizer,
    device=0,)
  
for results in pipe(KeyDataset(dataset, "text"), batch_size=8, truncation="only_first"):
    print(results)

# outputs = pipe(inputs) ↓
# preprocessed = pipe.preprocess(inputs)
# model_outputs = pipe.forward(preprocessed)
# outputs = pipe.postprocess(model_outputs)

result=pipe(
    [
        "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone",
        "Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne",
    ],
    num_return_sequences=2
)
```



## AudioClassificationPipeline

```python
transformers.pipeline( 
	task: str = None, model: typing.Optional = None, 
	config: typing.Union[str, transformers.configuration_utils.PretrainedConfig, NoneType] = None,
	tokenizer: typing.Union[str, transformers.tokenization_utils.PreTrainedTokenizer, NoneType] = None,
	feature_extractor: typing.Union[str, ForwardRef('SequenceFeatureExtractor'), NoneType] = None, 
	framework: typing.Optional[str] = None, 
	revision: typing.Optional[str] = None, 
	use_fast: bool = True, 
	use_auth_token: typing.Union[str, bool, NoneType] = None, 
	model_kwargs: typing.Dict[str, typing.Any] = None, 
	pipeline_class: typing.Optional[typing.Any] = None, 
	**kwargs ) → Pipeline

```



输入参数：

**model** (`str` or [PreTrainedModel](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/model#transformers.PreTrainedModel) or [TFPreTrainedModel](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/model#transformers.TFPreTrainedModel), *optional*) — pipeline要使用的模型结构，输入模型名称或者继承自 [PreTrainedModel](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/model#transformers.PreTrainedModel) (for PyTorch) 和 [TFPreTrainedModel](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/model#transformers.TFPreTrainedModel) (for TensorFlow)的模型。

**tokenizer** (`str` or [PreTrainedTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizer), *optional*) — pipeline中为模型编码输入数据的tokenizer(分词器)，输入可以是参数文件名称或者继承自[PreTrainedTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizer)的类，也可以在config里面设置。

**modelcard** (`str` or `ModelCard` *optional*) — Model card attributed to the model for this pipeline.

**framework** (`str`, *optional*) — 设置模型架构基础， `"pt"` 为PyTorch ， `"tf"` 为 TensorFlow。

**task** (`str`) — 定义pipeline要执行的任务：

**num_workers** (`int`, *optional*, defaults to 8) — When the pipeline will use *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the number of workers to be used.

**batch_size** (`int`, *optional*, defaults to 1) — When the pipeline will use *DataLoader* (when passing a dataset, on GPU for a Pytorch model), the size of the batch to use, for inference this is not always beneficial, please read [Batching with pipelines](https://huggingface.co/transformers/main_classes/pipelines.html#pipeline-batching) .

**args_parser** ([ArgumentHandler](https://huggingface.co/docs/transformers/v4.17.0/en/internal/pipelines_utils#transformers.pipelines.ArgumentHandler), *optional*) — Reference to the object in charge of parsing supplied pipeline parameters.

**device** (`int`, *optional*, defaults to -1) — Device ordinal for CPU/GPU supports. Setting this to -1 will leverage CPU, a positive will run the model on the associated CUDA device id.

**binary_output** (`bool`, *optional*, defaults to `False`) — Flag indicating if the output the pipeline should happen in a binary format (i.e., pickle) or as raw text.

Returns：[Pipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.Pipeline)

# AutoTokenizer.from_pretrained()

Parameters：

- **pretrained_model_name_or_path** (`str` or `os.PathLike`) — Can be either:A string, the *model id* of a predefined tokenizer hosted inside a model repo on huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.A path to a *directory* containing vocabulary files required by the tokenizer, for instance saved using the [save_pretrained()](https://huggingface.co/docs/transformers/v4.17.0/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained) method, e.g., `./my_model_directory/`.A path or url to a single saved vocabulary file if and only if the tokenizer only requires a single vocabulary file (like Bert or XLNet), e.g.: `./my_model_directory/vocab.txt`. (Not applicable to all derived classes)
- **inputs** (additional positional arguments, *optional*) — Will be passed along to the Tokenizer `__init__()` method.
- **config** ([PretrainedConfig](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/configuration#transformers.PretrainedConfig), *optional*) — The configuration object used to dertermine the tokenizer class to instantiate.
- **cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in which a downloaded pretrained model configuration should be cached if the standard cache should not be used.
- **force_download** (`bool`, *optional*, defaults to `False`) — Whether or not to force the (re-)download the model weights and configuration files and override the cached versions if they exist.
- **resume_download** (`bool`, *optional*, defaults to `False`) — Whether or not to delete incompletely received files. Will attempt to resume the download if such a file exists.
- **proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to use by protocol or endpoint, e.g., `{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}`. The proxies are used on each request.
- **revision(`str`,** *optional*, defaults to `"main"`) — The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any identifier allowed by git.
- **subfolder** (`str`, *optional*) — In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for facebook/rag-token-base), specify it here.
- **use_fast** (`bool`, *optional*, defaults to `True`) — Whether or not to try to load the fast version of the tokenizer.
- **tokenizer_type** (`str`, *optional*) — Tokenizer type to be loaded.
- **trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or not to allow for custom models defined on the Hub in their own modeling files. This option should only be set to `True` for repositories you trust and in which you have read the code, as it will execute code present on the Hub on your local machine.
- **kwargs** (additional keyword arguments, *optional*) — Will be passed to the Tokenizer `__init__()` method. Can be used to set special tokens like `bos_token`, `eos_token`, `unk_token`, `sep_token`, `pad_token`, `cls_token`, `mask_token`, `additional_special_tokens`. See parameters in the `__init__()` for more details.

Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary.

The tokenizer class to instantiate is selected based on the `model_type` property of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible), or when it’s missing, by falling back to using pattern matching on `pretrained_model_name_or_path`:

- **albert** — [AlbertTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/albert#transformers.AlbertTokenizer) or [AlbertTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/albert#transformers.AlbertTokenizerFast) (ALBERT model)
- **bart** — [BartTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/bart#transformers.BartTokenizer) or [BartTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/bart#transformers.BartTokenizerFast) (BART model)
- **barthez** — [BarthezTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/barthez#transformers.BarthezTokenizer) or [BarthezTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/barthez#transformers.BarthezTokenizerFast) (BARThez model)
- **bartpho** — [BartphoTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/bartpho#transformers.BartphoTokenizer) (BARTpho model)
- **bert** — [BertTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/bert#transformers.BertTokenizer) or [BertTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/bert#transformers.BertTokenizerFast) (BERT model)
- **bert-generation** — [BertGenerationTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/bert-generation#transformers.BertGenerationTokenizer) (Bert Generation model)
- **bert-japanese** — [BertJapaneseTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer) (BertJapanese model)
- **bertweet** — [BertweetTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/bertweet#transformers.BertweetTokenizer) (Bertweet model)
- **big_bird** — [BigBirdTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/big_bird#transformers.BigBirdTokenizer) or [BigBirdTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/big_bird#transformers.BigBirdTokenizerFast) (BigBird model)
- **bigbird_pegasus** — [PegasusTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/pegasus#transformers.PegasusTokenizer) or [PegasusTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/pegasus#transformers.PegasusTokenizerFast) (BigBirdPegasus model)
- **blenderbot** — [BlenderbotTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/blenderbot#transformers.BlenderbotTokenizer) or [BlenderbotTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast) (Blenderbot model)
- **blenderbot-small** — [BlenderbotSmallTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer) (BlenderbotSmall model)
- **byt5** — [ByT5Tokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/byt5#transformers.ByT5Tokenizer) (ByT5 model)
- **camembert** — [CamembertTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/camembert#transformers.CamembertTokenizer) or [CamembertTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/camembert#transformers.CamembertTokenizerFast) (CamemBERT model)
- **canine** — [CanineTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/canine#transformers.CanineTokenizer) (Canine model)
- **clip** — [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/clip#transformers.CLIPTokenizer) or [CLIPTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/clip#transformers.CLIPTokenizerFast) (CLIP model)
- **convbert** — [ConvBertTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/convbert#transformers.ConvBertTokenizer) or [ConvBertTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/convbert#transformers.ConvBertTokenizerFast) (ConvBERT model)
- **cpm** — [CpmTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/cpm#transformers.CpmTokenizer) or `CpmTokenizerFast` (CPM model)
- **ctrl** — [CTRLTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/ctrl#transformers.CTRLTokenizer) (CTRL model)
- **deberta** — [DebertaTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/deberta#transformers.DebertaTokenizer) or [DebertaTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/deberta#transformers.DebertaTokenizerFast) (DeBERTa model)
- **deberta-v2** — [DebertaV2Tokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer) (DeBERTa-v2 model)
- **distilbert** — [DistilBertTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/distilbert#transformers.DistilBertTokenizer) or [DistilBertTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/distilbert#transformers.DistilBertTokenizerFast) (DistilBERT model)
- **dpr** — [DPRQuestionEncoderTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer) or [DPRQuestionEncoderTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast) (DPR model)
- **electra** — [ElectraTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/electra#transformers.ElectraTokenizer) or [ElectraTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/electra#transformers.ElectraTokenizerFast) (ELECTRA model)
- **flaubert** — [FlaubertTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/flaubert#transformers.FlaubertTokenizer) (FlauBERT model)
- **fnet** — [FNetTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/fnet#transformers.FNetTokenizer) or [FNetTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/fnet#transformers.FNetTokenizerFast) (FNet model)
- **fsmt** — [FSMTTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/fsmt#transformers.FSMTTokenizer) (FairSeq Machine-Translation model)
- **funnel** — [FunnelTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/funnel#transformers.FunnelTokenizer) or [FunnelTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/funnel#transformers.FunnelTokenizerFast) (Funnel Transformer model)
- **gpt2** — [GPT2Tokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/gpt2#transformers.GPT2Tokenizer) or [GPT2TokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/gpt2#transformers.GPT2TokenizerFast) (OpenAI GPT-2 model)
- **gpt_neo** — [GPT2Tokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/gpt2#transformers.GPT2Tokenizer) or [GPT2TokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/gpt2#transformers.GPT2TokenizerFast) (GPT Neo model)
- **herbert** — [HerbertTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/herbert#transformers.HerbertTokenizer) or [HerbertTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/herbert#transformers.HerbertTokenizerFast) (HerBERT model)
- **hubert** — [Wav2Vec2CTCTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer) (Hubert model)
- **ibert** — [RobertaTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/roberta#transformers.RobertaTokenizer) or [RobertaTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/roberta#transformers.RobertaTokenizerFast) (I-BERT model)
- **layoutlm** — [LayoutLMTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/layoutlm#transformers.LayoutLMTokenizer) or [LayoutLMTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast) (LayoutLM model)
- **layoutlmv2** — [LayoutLMv2Tokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer) or [LayoutLMv2TokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast) (LayoutLMv2 model)
- **layoutxlm** — [LayoutXLMTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer) or [LayoutXLMTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast) (LayoutXLM model)
- **led** — [LEDTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/led#transformers.LEDTokenizer) or [LEDTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/led#transformers.LEDTokenizerFast) (LED model)
- **longformer** — [LongformerTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/longformer#transformers.LongformerTokenizer) or [LongformerTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/longformer#transformers.LongformerTokenizerFast) (Longformer model)
- **luke** — [LukeTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/luke#transformers.LukeTokenizer) (LUKE model)
- **lxmert** — [LxmertTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/lxmert#transformers.LxmertTokenizer) or [LxmertTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/lxmert#transformers.LxmertTokenizerFast) (LXMERT model)
- **m2m_100** — [M2M100Tokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/m2m_100#transformers.M2M100Tokenizer) (M2M100 model)
- **marian** — [MarianTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/marian#transformers.MarianTokenizer) (Marian model)
- **mbart** — [MBartTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/mbart#transformers.MBartTokenizer) or [MBartTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/mbart#transformers.MBartTokenizerFast) (mBART model)
- **mbart50** — [MBart50Tokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/mbart#transformers.MBart50Tokenizer) or [MBart50TokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/mbart#transformers.MBart50TokenizerFast) (mBART-50 model)
- **mluke** — [MLukeTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/mluke#transformers.MLukeTokenizer) (mLUKE model)
- **mobilebert** — [MobileBertTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/mobilebert#transformers.MobileBertTokenizer) or [MobileBertTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast) (MobileBERT model)
- **mpnet** — [MPNetTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/mpnet#transformers.MPNetTokenizer) or [MPNetTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/mpnet#transformers.MPNetTokenizerFast) (MPNet model)
- **mt5** — [MT5Tokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/mt5#transformers.T5Tokenizer) or [MT5TokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/mt5#transformers.T5TokenizerFast) (mT5 model)
- **openai-gpt** — [OpenAIGPTTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer) or [OpenAIGPTTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast) (OpenAI GPT model)
- **pegasus** — [PegasusTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/pegasus#transformers.PegasusTokenizer) or [PegasusTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/pegasus#transformers.PegasusTokenizerFast) (Pegasus model)
- **perceiver** — [PerceiverTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/perceiver#transformers.PerceiverTokenizer) (Perceiver model)
- **phobert** — [PhobertTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/phobert#transformers.PhobertTokenizer) (PhoBERT model)
- **plbart** — [PLBartTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/plbart#transformers.PLBartTokenizer) (PLBart model)
- **prophetnet** — [ProphetNetTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/prophetnet#transformers.ProphetNetTokenizer) (ProphetNet model)
- **qdqbert** — [BertTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/bert#transformers.BertTokenizer) or [BertTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/bert#transformers.BertTokenizerFast) (QDQBert model)
- **rag** — [RagTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/rag#transformers.RagTokenizer) (RAG model)
- **reformer** — [ReformerTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/reformer#transformers.ReformerTokenizer) or [ReformerTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/reformer#transformers.ReformerTokenizerFast) (Reformer model)
- **rembert** — [RemBertTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/rembert#transformers.RemBertTokenizer) or [RemBertTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/rembert#transformers.RemBertTokenizerFast) (RemBERT model)
- **retribert** — [RetriBertTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/retribert#transformers.RetriBertTokenizer) or [RetriBertTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/retribert#transformers.RetriBertTokenizerFast) (RetriBERT model)
- **roberta** — [RobertaTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/roberta#transformers.RobertaTokenizer) or [RobertaTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/roberta#transformers.RobertaTokenizerFast) (RoBERTa model)
- **roformer** — [RoFormerTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/roformer#transformers.RoFormerTokenizer) or [RoFormerTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/roformer#transformers.RoFormerTokenizerFast) (RoFormer model)
- **speech_to_text** — [Speech2TextTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer) (Speech2Text model)
- **speech_to_text_2** — [Speech2Text2Tokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer) (Speech2Text2 model)
- **splinter** — [SplinterTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/splinter#transformers.SplinterTokenizer) or [SplinterTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/splinter#transformers.SplinterTokenizerFast) (Splinter model)
- **squeezebert** — [SqueezeBertTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer) or [SqueezeBertTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast) (SqueezeBERT model)
- **t5** — [T5Tokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/mt5#transformers.T5Tokenizer) or [T5TokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/mt5#transformers.T5TokenizerFast) (T5 model)
- **tapas** — [TapasTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/tapas#transformers.TapasTokenizer) (TAPAS model)
- **transfo-xl** — [TransfoXLTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer) (Transformer-XL model)
- **wav2vec2** — [Wav2Vec2CTCTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer) (Wav2Vec2 model)
- **wav2vec2_phoneme** — [Wav2Vec2PhonemeCTCTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer) (Wav2Vec2Phoneme model)
- **xglm** — [XGLMTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/xglm#transformers.XGLMTokenizer) or [XGLMTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/xglm#transformers.XGLMTokenizerFast) (XGLM model)
- **xlm** — [XLMTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/xlm#transformers.XLMTokenizer) (XLM model)
- **xlm-prophetnet** — [XLMProphetNetTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer) (XLMProphetNet model)
- **xlm-roberta** — [XLMRobertaTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer) or [XLMRobertaTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast) (XLM-RoBERTa model)
- **xlnet** — [XLNetTokenizer](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/xlnet#transformers.XLNetTokenizer) or [XLNetTokenizerFast](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/xlnet#transformers.XLNetTokenizerFast) (XLNet model)



# AutoFeatureExtractor.AutoFeatureExtractor()

Parameters

- **pretrained_model_name_or_path** (`str` or `os.PathLike`) — This can be either:a string, the *model id* of a pretrained feature_extractor hosted inside a model repo on huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.a path to a *directory* containing a feature extractor file saved using the [save_pretrained()](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained) method, e.g., `./my_model_directory/`.a path or url to a saved feature extractor JSON *file*, e.g., `./my_model_directory/preprocessor_config.json`.
- **cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in which a downloaded pretrained model feature extractor should be cached if the standard cache should not be used.
- **force_download** (`bool`, *optional*, defaults to `False`) — Whether or not to force to (re-)download the feature extractor files and override the cached versions if they exist.
- **resume_download** (`bool`, *optional*, defaults to `False`) — Whether or not to delete incompletely received file. Attempts to resume the download if such a file exists.
- **proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to use by protocol or endpoint, e.g., `{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.
- **use_auth_token** (`str` or *bool*, *optional*) — The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated when running `transformers-cli login` (stored in `~/.huggingface`).
- **revision(`str`,** *optional*, defaults to `"main"`) — The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any identifier allowed by git.
- **return_unused_kwargs** (`bool`, *optional*, defaults to `False`) — If `False`, then this function returns just the final feature extractor object. If `True`, then this functions returns a `Tuple(feature_extractor, unused_kwargs)` where *unused_kwargs* is a dictionary consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of `kwargs` which has not been used to update `feature_extractor` and is otherwise ignored.
- **trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or not to allow for custom models defined on the Hub in their own modeling files. This option should only be set to `True` for repositories you trust and in which you have read the code, as it will execute code present on the Hub on your local machine.
- **kwargs** (`Dict[str, Any]`, *optional*) — The values in kwargs of any keys which are feature extractor attributes will be used to override the loaded values. Behavior concerning key/value pairs whose keys are *not* feature extractor attributes is controlled by the `return_unused_kwargs` keyword parameter.

Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary.

The feature extractor class to instantiate is selected based on the `model_type` property of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible), or when it’s missing, by falling back to using pattern matching on `pretrained_model_name_or_path`:

- **beit** — [BeitFeatureExtractor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/beit#transformers.BeitFeatureExtractor) (BEiT model)
- **clip** — [CLIPFeatureExtractor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/clip#transformers.CLIPFeatureExtractor) (CLIP model)
- **convnext** — [ConvNextFeatureExtractor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/convnext#transformers.ConvNextFeatureExtractor) (ConvNext model)
- **deit** — [DeiTFeatureExtractor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/deit#transformers.DeiTFeatureExtractor) (DeiT model)
- **detr** — [DetrFeatureExtractor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/detr#transformers.DetrFeatureExtractor) (DETR model)
- **hubert** — [Wav2Vec2FeatureExtractor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor) (Hubert model)
- **layoutlmv2** — [LayoutLMv2FeatureExtractor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor) (LayoutLMv2 model)
- **perceiver** — [PerceiverFeatureExtractor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor) (Perceiver model)
- **poolformer** — [PoolFormerFeatureExtractor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor) (PoolFormer model)
- **segformer** — [SegformerFeatureExtractor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/segformer#transformers.SegformerFeatureExtractor) (SegFormer model)
- **speech_to_text** — [Speech2TextFeatureExtractor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor) (Speech2Text model)
- **swin** — [ViTFeatureExtractor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/vit#transformers.ViTFeatureExtractor) (Swin model)
- **vit** — [ViTFeatureExtractor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/vit#transformers.ViTFeatureExtractor) (ViT model)
- **vit_mae** — [ViTFeatureExtractor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/vit#transformers.ViTFeatureExtractor) (ViTMAE model)
- **wav2vec2** — [Wav2Vec2FeatureExtractor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor) (Wav2Vec2 model)



### AutoProcessor.from_pretrained()

Parameters

- **pretrained_model_name_or_path** (`str` or `os.PathLike`) — This can be either:a string, the *model id* of a pretrained feature_extractor hosted inside a model repo on huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.a path to a *directory* containing a processor files saved using the `save_pretrained()` method, e.g., `./my_model_directory/`.
- **cache_dir** (`str` or `os.PathLike`, *optional*) — Path to a directory in which a downloaded pretrained model feature extractor should be cached if the standard cache should not be used.
- **force_download** (`bool`, *optional*, defaults to `False`) — Whether or not to force to (re-)download the feature extractor files and override the cached versions if they exist.
- **resume_download** (`bool`, *optional*, defaults to `False`) — Whether or not to delete incompletely received file. Attempts to resume the download if such a file exists.
- **proxies** (`Dict[str, str]`, *optional*) — A dictionary of proxy servers to use by protocol or endpoint, e.g., `{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.
- **use_auth_token** (`str` or *bool*, *optional*) — The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated when running `transformers-cli login` (stored in `~/.huggingface`).
- **revision** (`str`, *optional*, defaults to `"main"`) — The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any identifier allowed by git.
- **return_unused_kwargs** (`bool`, *optional*, defaults to `False`) — If `False`, then this function returns just the final feature extractor object. If `True`, then this functions returns a `Tuple(feature_extractor, unused_kwargs)` where *unused_kwargs* is a dictionary consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of `kwargs` which has not been used to update `feature_extractor` and is otherwise ignored.
- **trust_remote_code** (`bool`, *optional*, defaults to `False`) — Whether or not to allow for custom models defined on the Hub in their own modeling files. This option should only be set to `True` for repositories you trust and in which you have read the code, as it will execute code present on the Hub on your local machine.
- **kwargs** (`Dict[str, Any]`, *optional*) — The values in kwargs of any keys which are feature extractor attributes will be used to override the loaded values. Behavior concerning key/value pairs whose keys are *not* feature extractor attributes is controlled by the `return_unused_kwargs` keyword parameter.

Instantiate one of the processor classes of the library from a pretrained model vocabulary.

The processor class to instantiate is selected based on the `model_type` property of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible):

- **clip** — [CLIPProcessor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/clip#transformers.CLIPProcessor) (CLIP model)
- **layoutlmv2** — [LayoutLMv2Processor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor) (LayoutLMv2 model)
- **layoutxlm** — [LayoutXLMProcessor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor) (LayoutXLM model)
- **speech_to_text** — [Speech2TextProcessor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/speech_to_text#transformers.Speech2TextProcessor) (Speech2Text model)
- **speech_to_text_2** — [Speech2Text2Processor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor) (Speech2Text2 model)
- **trocr** — [TrOCRProcessor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/trocr#transformers.TrOCRProcessor) (TrOCR model)
- **vision-text-dual-encoder** — [VisionTextDualEncoderProcessor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor) (VisionTextDualEncoder model)
- **wav2vec2** — [Wav2Vec2Processor](https://huggingface.co/docs/transformers/v4.17.0/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor) (Wav2Vec2 model)





# Configuration



```
from transformers import Wav2Vec2Config,Wav2Vec2Model

my_config = Wav2Vec2Config(activation="relu", attention_dropout=0.4)
print(my_config)

my_config = Wav2Vec2Config.from_pretrained("wav2vec2-base-uncased", activation="relu", attention_dropout=0.4)

my_config.save_pretrained(save_directory="./your_model_save_path")

model = Wav2Vec2Model(my_config)
model = Wav2Vec2Model.from_pretrained("distilbert-base-uncased", config=my_config)
```



```
from transformers import Wav2Vec2CTCTokenizer,Wav2Vec2FeatureExtractor

feature_extractor = Wav2Vec2FeatureExtractor(padding_value=1.0, do_normalize=True)

tokenizer = Wav2Vec2CTCTokenizer(vocab_file="my_vocab_file.txt")
processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)
```





# Fine-tune

```python
from datasets import load_dataset

# 加载数据
dataset = load_dataset("yelp_review_full")
# def tokenize_function: pass
tokenized_datasets = dataset.map(tokenize_function, batched=True)
train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))

# 构造数据迭代器
from torch.utils.data import DataLoader

train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8)
eval_dataloader = DataLoader(eval_dataset, batch_size=8)

# 下载模型
from transformers import AutoModelForSequenceClassification
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)

# 定义优化器
from torch.optim import AdamW
optimizer = AdamW(model.parameters(), lr=5e-5)

# 定义学习率调整器
from transformers import get_scheduler
num_epochs = 3
num_training_steps = num_epochs * len(train_dataloader)
lr_scheduler = get_scheduler(
    name="linear", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps
)

# 设置GPU设备
import torch
device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
model.to(device)


from tqdm.auto import tqdm
progress_bar = tqdm(range(num_training_steps))
model.train()
for epoch in range(num_epochs):
    for batch in train_dataloader:
        batch = {k: v.to(device) for k, v in batch.items()}
        outputs = model(**batch)
        loss = outputs.loss
        loss.backward()

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)
        
# 评估模型
from datasets import load_metric
metric = load_metric("accuracy")
model.eval()
for batch in eval_dataloader:
    batch = {k: v.to(device) for k, v in batch.items()}
    with torch.no_grad():
        outputs = model(**batch)

    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)
    metric.add_batch(predictions=predictions, references=batch["labels"])

metric.compute()
```



